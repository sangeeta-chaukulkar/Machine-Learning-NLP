{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bde8da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c307d6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spamdata.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6a3a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850176c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae8e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "def clean_text(text):\n",
    "    cleaned = text.lower()\n",
    "    \n",
    "    ## remove punctuations\n",
    "    punctuations = string.punctuation\n",
    "    cleaned = \"\".join(character for character in cleaned if character not in punctuations)\n",
    "    \n",
    "    my_doc = nlp(cleaned)\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "    \n",
    "    filtered_sentence =[] \n",
    "    ## removing stopwords \n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word)\n",
    "    \n",
    "    cleaned = filtered_sentence\n",
    "    cleaned = \" \".join(cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17d2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cleaned\"] = data[\"text\"].apply(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b55708d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun early hor u c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah nt think goes usf lives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  jurong point crazy available bugis n great wor...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                                u dun early hor u c  \n",
       "4                        nah nt think goes usf lives  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cd4e6",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e195a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words in text\n",
    "data[\"word_count\"] = data[\"text\"].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97f4686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words in cleaned text\n",
    "data[\"word_count_cleand\"] = data[\"cleaned\"].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc9ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of characters including spaces in the cleaned text\n",
    "data[\"char_count\"] = data[\"cleaned\"].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e72c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of characters excluding spaces in the cleaned text\n",
    "data[\"char_count_without_spaces\"] = data[\"cleaned\"].apply(lambda x : len(x.replace(\" \",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb5c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of digits in the cleaned text\n",
    "data[\"num_dig\"] = data[\"cleaned\"].apply(lambda x :  sum([1 if w.isdigit() else 0 for w in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9204d376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleand</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_dig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>131</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun early hor u c</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah nt think goes usf lives</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  jurong point crazy available bugis n great wor...          20   \n",
       "1                            ok lar joking wif u oni           6   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...          28   \n",
       "3                                u dun early hor u c          11   \n",
       "4                        nah nt think goes usf lives          13   \n",
       "\n",
       "   word_count_cleand  char_count  char_count_without_spaces  num_dig  \n",
       "0                 15          79                         65        0  \n",
       "1                  6          23                         18        0  \n",
       "2                 22         131                        110        3  \n",
       "3                  6          19                         14        0  \n",
       "4                  6          27                         22        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89705d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8763fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dic = {\"noun\" : [\"NNP\", \"NN\", \"NNS\", \"NNPS\"], \"verb\" : [\"VBZ\", \"VB\", \"VBD\",\"VBG\", \"VBN\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99c503cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for noun and verb counts\n",
    "def pos_check(txt, family):\n",
    "\n",
    "    # spacy document\n",
    "    txt = nlp(txt)\n",
    "    \n",
    "    all_tags = []\n",
    "\n",
    "    # Get pos tag\n",
    "    for w in txt:\n",
    "        all_tags.append(w.tag_)\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    # Count number of nouns and verbs\n",
    "    for tag in all_tags:\n",
    "        if tag in pos_dic[family]:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f793264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"noun_count\"] = data[\"cleaned\"].apply(lambda x : pos_check(x, \"noun\"))\n",
    "data[\"verb_count\"] = data[\"cleaned\"].apply(lambda x : pos_check(x, \"verb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca7bb77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleand</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_dig</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>131</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun early hor u c</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah nt think goes usf lives</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  jurong point crazy available bugis n great wor...          20   \n",
       "1                            ok lar joking wif u oni           6   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...          28   \n",
       "3                                u dun early hor u c          11   \n",
       "4                        nah nt think goes usf lives          13   \n",
       "\n",
       "   word_count_cleand  char_count  char_count_without_spaces  num_dig  \\\n",
       "0                 15          79                         65        0   \n",
       "1                  6          23                         18        0   \n",
       "2                 22         131                        110        3   \n",
       "3                  6          19                         14        0   \n",
       "4                  6          27                         22        0   \n",
       "\n",
       "   noun_count  verb_count  \n",
       "0           7           1  \n",
       "1           4           1  \n",
       "2          10           1  \n",
       "3           5           0  \n",
       "4           1           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ad35c",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "947b4722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding target variable\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "target = data[\"label\"].values\n",
    "target = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9062eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data.drop(['label','text','cleaned'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c79df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, target, random_state=20, stratify=target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e277990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4457, 7), (4457,)), ((1115, 7), (1115,)))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape, y_train.shape), (x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e169c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0781564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bf058ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b7313cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "\n",
    "pred_valid = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a16676f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9fa2bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9409916984518735"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a23ef20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363228699551569"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, pred_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5bfbd",
   "metadata": {},
   "source": [
    "# TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2dff643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tf-Idf Vectoriser\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ecc1d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tfidf = TfidfVectorizer(max_features=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52effc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=250)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tfidf.fit(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb3bb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_tfidf = word_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ddd768ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x250 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16825 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec99bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining meta features and Tf-Idf features\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# features\n",
    "features = data.drop(['label','text','cleaned'],axis=1)\n",
    "\n",
    "# Combined features\n",
    "train = hstack([word_vectors_tfidf, csr_matrix(features)], \"csr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26fdd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train, target, random_state=20, stratify=target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2a4bed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4457, 257), (4457,)), ((1115, 257), (1115,)))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape, y_train.shape), (x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8701f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "69a23860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bfca0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "\n",
    "pred_valid = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8dc1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e69cc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=f1_score(pred_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "714fbc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score is  0.8743961352657004\n"
     ]
    }
   ],
   "source": [
    "print(\"Training F1 score is \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ab643b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=f1_score(pred_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5152324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score is  0.8698412698412697\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation F1 score is \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd044f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
